{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FastAPI + Docker + Streamlit\n",
    "\n",
    "reference: https://www.analyticsvidhya.com/blog/2023/02/build-and-deploy-an-ml-model-app-using-streamlit-docker-and-gke/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have a dataset, did some data analysis, and built a model around it; now, what? The next step will be to deploy the model on a server, so your model will be accessible to the general public or your development team to integrate it with the app. \n",
    "\n",
    "So, in this notebook, you will learn how to\n",
    "\n",
    "- Serve a machine learning model for predicting employee churn as a Web service using Fast API.\n",
    "- Create a simple web front end using Streamlit.\n",
    "- Dockerizing the Streamlit app and API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>Departments</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                0.38             0.53               2                   157   \n",
       "1                0.80             0.86               5                   262   \n",
       "2                0.11             0.88               7                   272   \n",
       "3                0.72             0.87               5                   223   \n",
       "4                0.37             0.52               2                   159   \n",
       "\n",
       "   time_spend_company  Work_accident  left  promotion_last_5years Departments  \\\n",
       "0                   3              0     1                      0       sales   \n",
       "1                   6              0     1                      0       sales   \n",
       "2                   4              0     1                      0       sales   \n",
       "3                   5              0     1                      0       sales   \n",
       "4                   3              0     1                      0       sales   \n",
       "\n",
       "   salary  \n",
       "0     low  \n",
       "1  medium  \n",
       "2  medium  \n",
       "3     low  \n",
       "4     low  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('example4_dc.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode categorical data\n",
    "enc = LabelEncoder()\n",
    "df['Departments'] = enc.fit_transform(df['Departments'])\n",
    "df['salary'] = enc.fit_transform(df['salary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split training-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['left']\n",
    "df.drop('left', axis=1, inplace=True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(df, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries for model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a custom switcher class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_classifier(BaseEstimator,):\n",
    "    def __init__(self, estimator=None):\n",
    "        self.estimator = estimator\n",
    "    def fit(self, X, y=None):\n",
    "        self.estimator.fit(X,y)\n",
    "        return self\n",
    "    def predict(self, X, y=None):\n",
    "        return self.estimator.predict(X,y)\n",
    "    def predict_proba(self, X):\n",
    "        return self.estimator.predict_proba(X)\n",
    "    def score(self, X, y):\n",
    "        return self.estimator.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pipeline and pass parameters. We will be using a Random Forest classifier with multiple hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([ ('clf', my_classifier())])\n",
    "parameters = [\n",
    "             {'clf':[RandomForestClassifier()],\n",
    "             'clf__n_estimators': [75, 100, 125,],\n",
    "             'clf__min_samples_split': [2,4,6],\n",
    "             'clf__max_depth': [5, 10, 15,]\n",
    "             },\n",
    "           ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a GridsearchCV object and fit the model with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, parameters, cv=5, scoring='roc_auc')\n",
    "grid.fit(x_train,y_train)\n",
    "#\n",
    "model = grid.best_estimator_\n",
    "score = grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pickle to serialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Rest API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to wrap our model with a Rest API. This allows us to access our saved model as and when required. We can get our prediction via an HTTP request to an API endpoint. For this, we will be using Fast API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from joblib import load\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the FastAPI class and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI()\n",
    "model  = load('model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a pydantic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class user_input(BaseModel):\n",
    "    satisfaction_level  : float\n",
    "    last_evaluation     : float\n",
    "    number_project      : int\n",
    "    average_montly_hours: int\n",
    "    time_spend_company  : int\n",
    "    Work_accident       : int  \n",
    "    promotion_last_5years: int\n",
    "    departments          : str\n",
    "    salary              : str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a prediction class to convert data in the appropriate format for predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data):\n",
    "    departments_list = ['IT', 'RandD', 'accounting', 'hr', 'management', 'marketing', 'product_mng', 'sales', 'support', 'technical']\n",
    "    data[-2] = departments_list.index(data[-2])\n",
    "    salaries = ['low', 'medium', 'high']\n",
    "    data[-1] = salaries.index(data[-1])\n",
    "    columns = ['satisfaction_level', 'last_evaluation', \n",
    "                'number_project', 'average_montly_hours', 'time_spend_company', \n",
    "                'Work_accident', 'promotion_last_5years','departments', 'salary']\n",
    "    prediction = model.predict( pd.DataFrame([data], columns= columns))\n",
    "    proba = model.predict_proba(pd.DataFrame([data], columns= columns))\n",
    "    return prediction, proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Base Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get('/')\n",
    "def welcome():\n",
    "    return f'Welcome to our app api'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an endpoint for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post('/predict')\n",
    "def func(Input:user_input):\n",
    "    data = [Input.satisfaction_level, Input.last_evaluation, \n",
    "            Input.number_project, Input.average_montly_hours, \n",
    "            Input.time_spend_company, Input.Work_accident, \n",
    "            Input.promotion_last_5years, Input.departments, Input.salary]\n",
    "    pred, proba = predict(data)\n",
    "    output = {'prediction':int(pred[0]), 'probability':float(proba[0][1])}\n",
    "    return json.dumps(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the API, run the below script on your terminal\n",
    "\n",
    "```bash\n",
    "unicorn main:app --reload\n",
    "```\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streamlit app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a new file called streamlit-app.py and add the below code to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.title('End-to-End App') #title to be shown\n",
    "st.header('Enter the employee data:') #header to be shown in app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create input forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satisfaction_level = st.number_input('satisfaction level',min_value=0.00, max_value=1.00)\n",
    "last_evaluation = st.number_input('last evaluation score',min_value=0.00, max_value=1.00)\n",
    "number_project = st.number_input('number of projects',min_value=1)\n",
    "average_montly_hours = st.slider('average monthly hours', min_value=0, max_value=320)\n",
    "time_spend_company = st.number_input(label = 'Number of years at company', min_value=0)\n",
    "Work_accident = st.selectbox('If met an accident at work', [1,0], index = 1)\n",
    "promotion_last_5years = st.selectbox('Promotion in last 5 years yes=1/no=0', [1,0], index=1)\n",
    "departments = st.selectbox('Department', ['IT', 'RandD', 'accounting', 'hr', 'management', 'marketing', 'product_mng', 'sales', 'support', 'technical'])\n",
    "salary = st.selectbox('Salary Band', ['low', 'medium', 'high',])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary of the above variables with keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['satisfaction_level', 'last_evaluation', 'number_project',\n",
    "       'average_montly_hours', 'time_spend_company', 'Work_accident',\n",
    "       'promotion_last_5years', 'departments', 'salary']\n",
    "params = [satisfaction_level, last_evaluation, number_project,\n",
    "       average_montly_hours, time_spend_company, Work_accident,\n",
    "       promotion_last_5years, departments, salary]\n",
    "input_data = dict(zip(names, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if st.button('Predict'):\n",
    "    #pred = predict(satisfaction_level, last_evaluation, number_project, average_montly_hours, time_spend_company, \n",
    "    #                                         Work_accident, promotion_last_5years,department, salary)\n",
    "    try:\n",
    "        output_ = requests.post(url = 'http://localhost:8000/predict', data = json.dumps(input_data))\n",
    "    except:\n",
    "       print('Not able to connect to api server')\n",
    "    #output_ = requests.post(url = 'http://localhost:8000/predict', data = json.dumps(input_data))\n",
    "    ans = eval(output_.json())\n",
    "    output = 'Yes' if ans['prediction']==1 else 'No'\n",
    "    if output == 'Yes':\n",
    "        st.success(f\"The employee might leave the company with a probability of {(ans['probability'])*100: .2f}\")\n",
    "    if output == 'No':\n",
    "        st.success(f\"The employee might not leave the company with a probability of {(1-ans['probability'])*100: .2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To launch the app, type the code bellow\n",
    "\n",
    "```bash\n",
    "streamlit run streamlit-app.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Containerzing the App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Dockerize the apps, we first need to create a docker file for each component in their respective directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dockerfile for Rest API\n",
    "\n",
    "```Dockerfile\n",
    "FROM python:3.9\n",
    "\n",
    "COPY requirements.txt app/requirements.txt\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "COPY . /app\n",
    "\n",
    "EXPOSE 8000\n",
    "\n",
    "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\" , \"--reload\"]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To elaborate on the last command in the backend Dockerfile, the following are the defined settings for Uvicorn:\n",
    "\n",
    "— host 0.0.0.0 defines the address to host the server on.\n",
    "\n",
    "— port 8008 defines the port to host the server on.\n",
    "\n",
    "main:app tells Uvicorn where it can find the FastAPI ASGI application — e.g., “within the the ‘main.py’ file, you’ll find the ASGI app, app = FastAPI().\n",
    "\n",
    "— reload enables auto-reload so the server will restart after changes are made to the code base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to add the requirements.txt file in the same directory as the Dockerfile. The requirements.txt file contains all the libraries that are required to run the API.\n",
    "\n",
    "```bash\n",
    "pip freeze > requirements.txt\n",
    "```\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a docker file for the Streamlit app\n",
    "\n",
    "```Dockerfile\n",
    "\n",
    "# frontent/Dockerfile\n",
    "\n",
    "FROM python:3.9\n",
    "\n",
    "COPY requirements.txt app/requirements.txt\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "COPY . /app\n",
    "\n",
    "EXPOSE 8501\n",
    "\n",
    "ENTRYPOINT [\"streamlit\",\"run\"]\n",
    "CMD [\"app.py\"]\n",
    "    \n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker Composer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normaly we would have to build each docker file separately and run them individually. But with docker composer, we can run all the docker files at once!!\n",
    "\n",
    "Docker Compose is used when we have a seperate docker file for each component of the app. In our case, we have two docker files, one for the API(backend) and the other for the Streamlit app(frontend)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a docker-compose.yml file in the root directory of the project. The docker-compose.yml file contains all the information required to run the app. \n",
    "\n",
    "```yml\n",
    "version: \"2\"\n",
    "services:\n",
    "  app:\n",
    "    build: ./frontend\n",
    "    ports: \n",
    "      - '8501:8501'\n",
    "  main:\n",
    "    build: ./backend\n",
    "    ports:\n",
    "      - '8000:8000'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our project structure\n",
    "```bash\n",
    "├── docker-compose.yml\n",
    "├── backend\n",
    "├── misc\n",
    "└── frontend\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then to run our docker composer\n",
    "\n",
    "```bash\n",
    "docker-compose up -d --build\n",
    "```\n",
    "\n",
    "Two containers will be running!\n",
    "\n",
    "Next time you dont need to rebuid the images\n",
    "\n",
    "```bash\n",
    "docker-compose up -d\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
