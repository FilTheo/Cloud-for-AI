{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by importing the necessary dependencies. You will be using `pickle` for loading the pre-trained model saved in the `app/wine.pkl` file, `numpy` for tensor manipulation, and the rest for developing the web server with `FastAPI`.\n",
    "\n",
    "Also, create an instance of the `FastAPI` class. This instance will handle all of the functionalities for the server:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "app = FastAPI(title=\"Predicting Wine Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you need a way to represent a data point. You can do this by creating a class the subclasses from pydantic's `BaseModel` and listing each attribute along with its corresponding type.\n",
    "\n",
    "In this case a data point represents a wine so this class is called `Wine` and all of the features of the model are of type `float`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represents a particular wine (or datapoint)\n",
    "class Wine(BaseModel):\n",
    "    alcohol: float\n",
    "    malic_acid: float\n",
    "    ash: float\n",
    "    alcalinity_of_ash: float\n",
    "    magnesium: float\n",
    "    total_phenols: float\n",
    "    flavanoids: float\n",
    "    nonflavanoid_phenols: float\n",
    "    proanthocyanins: float\n",
    "    color_intensity: float\n",
    "    hue: float\n",
    "    od280_od315_of_diluted_wines: float\n",
    "    proline: float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to load the classifier into memory so it can be used for prediction. This can be done in the global scope of the script but here it is done inside a function to show you a cool feature of FastAPI.\n",
    "\n",
    "If you decorate a function with the `@app.on_event(\"startup\")` decorator you ensure that the function is run at the startup of the server. This gives you some flexibility if you need some custom logic to be triggered right when the server starts.\n",
    "\n",
    "The classifier is opened using a context manager and assigned to the `clf` variable, which you still need to make global so other functions can access it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.on_event(\"startup\")\n",
    "def load_clf():\n",
    "    # Load classifier from pickle file\n",
    "    with open(\"/app/wine.pkl\", \"rb\") as file:\n",
    "        global clf\n",
    "        clf = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally you need to create the function that will handle the prediction. This function will be run when you visit the `/predict` endpoint of the server and it expects a `Wine` data point.\n",
    "\n",
    "This function is actually very straightforward, first you will convert the information within the `Wine` object into a numpy array of shape `(1, 13)` and then use the `predict` method of the classifier to make a prediction for the data point. Notice that the prediction must be casted into a list using the `tolist` method.\n",
    "\n",
    "Finally return a dictionary (which FastAPI will convert into `JSON`) containing the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post(\"/predict\")\n",
    "def predict(wine: Wine):\n",
    "    data_point = np.array(\n",
    "        [\n",
    "            [\n",
    "                wine.alcohol,\n",
    "                wine.malic_acid,\n",
    "                wine.ash,\n",
    "                wine.alcalinity_of_ash,\n",
    "                wine.magnesium,\n",
    "                wine.total_phenols,\n",
    "                wine.flavanoids,\n",
    "                wine.nonflavanoid_phenols,\n",
    "                wine.proanthocyanins,\n",
    "                wine.color_intensity,\n",
    "                wine.hue,\n",
    "                wine.od280_od315_of_diluted_wines,\n",
    "                wine.proline,\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pred = clf.predict(data_point).tolist()\n",
    "    pred = pred[0]\n",
    "    print(pred)\n",
    "    return {\"Prediction\": pred}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the server's code is ready for inference, although you still need to spin it up. If you want to try it locally (given that you have the required dependencies installed) you can do so by using the command `uvicorn main:app --reload` while on the same directory as the `main.py` file. **However this is not required as you will be dockerizing this server next**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dockerize the server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going forward all commands are run assuming you are currently within the `no-batch/` directory.\n",
    "\n",
    "Also you should create a directory called `app` and place `main.py` (the server) and its dependencies (`wine.pkl`) there as explained on the official FastAPI [docs](https://fastapi.tiangolo.com/deployment/docker/) on how to deploy with Docker. This should result in a directory structure that looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "└── example_2\n",
    "    ├── app/\n",
    "    │   ├── main.py (server code)\n",
    "    │   └── wine.pkl (serialized classifier)\n",
    "    ├── requirements.txt (Python dependencies)\n",
    "    ├── wine-examples/ (wine examples to test the server)\n",
    "    ├── README.md (this file)\n",
    "    └── Dockerfile\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Dockerfile` is made up of all the instructions required to build your image. If this is the first time you see this kind of file it might look intimidating but you will see it is actually easier than it looks. First take a look at the whole file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Dockerfile\n",
    "FROM python3.7:slim\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could use many different base images such as the official `python:3.7` image. However if you compared the size you will encounter it is a lot heavier. In this case you will be using the one mentioned above as it is a great minimal image for the task at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Installing dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have an environment with Python installed it is time to install all of the Python packages that your server will depend on. First you need to copy your local `requirements.txt` file into the image so it can be accessed by other processes, this can be done via the `COPY` instruction:\n",
    "\n",
    "```Dockerfile\n",
    "COPY requirements.txt .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can use `pip` to install these Python libraries. To run any command as you would on `bash`, use the `RUN` instruction:\n",
    "```Dockerfile\n",
    "RUN pip install -r requirements.txt && \\\n",
    "\trm requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that two commands were chained together using the `&&` operator. After you installed the libraries specified within `requirements.txt` you don't have more use for that file so it is a good idea to delete it so the image includes only the necessary files for your server to run.\n",
    "\n",
    "This can be done using two `RUN` instructions, however, it is a good practice to chain together commands in this manner since Docker creates a new layer every time it encounters a `RUN`, `COPY` or `ADD` instruction. This will result in a bigger image size. If you are interest in best practices for writing Dockerfiles be sure to check out this [resource](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exposing the port"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you are coding a web server it is a good idea to leave some documentation about the port that the server is going to listen on. You can do this with the `EXPOSE` instruction. In this case the server will listen to requests on port 80: \n",
    "\n",
    "```Dockerfile\n",
    "EXPOSE 80\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Copying your server into the image\n",
    "\n",
    "Now you should put your code within the image. To do this you can simply use the `COPY` instruction to copy the `app` directory within the root of the container:\n",
    "\n",
    "```Dockerfile\n",
    "COPY ./app /app\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spinning up the server\n",
    "\n",
    "Containers are usually meant to start and carry out a single task. This is why the `CMD` instruction was created. This is the command that will be run once a container that uses this image is started. In this case it is the command that will spin up the server by specifying the host and port. Notice that the command is written in a `JSON` like format having each part of the command as a string within a list:\n",
    "\n",
    "```Dockerfile\n",
    "CMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"80\"]\n",
    "```\n",
    "\n",
    "What is meant by `JSON` like format is that Docker uses `JSON` for its configurations and the `CMD` instruction expects the commands as a list that follows `JSON` conventions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Putting it all together\n",
    "\n",
    "```Dockerfile\n",
    "FROM frolvlad/alpine-miniconda3:python3.7\n",
    "\n",
    "COPY requirements.txt .\n",
    "\n",
    "RUN pip install -r requirements.txt && \\\n",
    "\trm requirements.txt\n",
    "\n",
    "EXPOSE 80\n",
    "\n",
    "COPY ./app /app\n",
    "\n",
    "CMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"80\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the image\n",
    "\n",
    "Now that the `Dockerfile` is ready and you understand its contents, it is time to build the image. To do so, double check that you are within the `no-batch` directory and use the `docker build` command.\n",
    "```bash\n",
    "docker build -t name_of_the_app .\n",
    "```\n",
    "\n",
    "You can use the `-t` flag to specify the name of the image. Do not forget the .\n",
    "\n",
    "After a couple of minutes your image should be ready to be used! If you want to see it along with any other images that you have on your local machine use the `docker images` command. This will display all of you images alongside their names, tags and size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the container\n",
    "\n",
    "Now that the image has been successfully built it is time to run a container out of it. You can do so by using the following command:\n",
    "\n",
    "```bash\n",
    "docker run --rm -p 80:80 name_of_the_app\n",
    "```\n",
    "\n",
    "You should recognize this command from a previous ungraded lab. Let's do a quick recap of the flags used:\n",
    "- `--rm`: Delete this container after stopping running it. This is to avoid having to manually delete the container. Deleting unused containers helps your system to stay clean and tidy.\n",
    "- `-p 80:80`: This flags performs an operation knows as port mapping. The container, as well as your local machine, has its own set of ports. So you are able to access the port 80 within the container, you need to map it to a port on your computer. In this case it is mapped to the port 80 in your machine. \n",
    "\n",
    "At the end of the command is the name and tag of the image you want to run. \n",
    "\n",
    "After some seconds the container will start and spin up the server within. You should be able to see FastAPI's logs being printed in the terminal. \n",
    "\n",
    "Now head over to [localhost:80](http://localhost:80) and you should see a message about the server spinning up correctly.\n",
    "\n",
    "**Nice work!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make requests to the server\n",
    "\n",
    "Now that the server is listening to requests on port 80, you can send `POST` requests to it for predicting classes of wine. \n",
    "\n",
    "Every request should contain the data that represents a wine in `JSON` format like this:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"alcohol\":12.6,\n",
    "  \"malic_acid\":1.34,\n",
    "  \"ash\":1.9,\n",
    "  \"alcalinity_of_ash\":18.5,\n",
    "  \"magnesium\":88.0,\n",
    "  \"total_phenols\":1.45,\n",
    "  \"flavanoids\":1.36,\n",
    "  \"nonflavanoid_phenols\":0.29,\n",
    "  \"proanthocyanins\":1.35,\n",
    "  \"color_intensity\":2.45,\n",
    "  \"hue\":1.04,\n",
    "  \"od280_od315_of_diluted_wines\":2.77,\n",
    "  \"proline\":562.0\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example represents a class 1 wine.\n",
    "\n",
    "Remember from Course 1 that FastAPI has a built-in client for you to interact with the server. You can use it by visiting [localhost:80/docs](http://localhost:80/docs)\n",
    "\n",
    "You can also use `curl` and send the data directly with the request like this (notice that you need to open a new terminal window for this as the one you originally used to spin up the server is logging info and is not usable until you stop it):\n",
    "\n",
    "```bash\n",
    "curl -X 'POST' http://localhost/predict \\\n",
    "  -H 'Content-Type: application/json' \\\n",
    "  -d '{\n",
    "  \"alcohol\":12.6,\n",
    "  \"malic_acid\":1.34,\n",
    "  \"ash\":1.9,\n",
    "  \"alcalinity_of_ash\":18.5,\n",
    "  \"magnesium\":88.0,\n",
    "  \"total_phenols\":1.45,\n",
    "  \"flavanoids\":1.36,\n",
    "  \"nonflavanoid_phenols\":0.29,\n",
    "  \"proanthocyanins\":1.35,\n",
    "  \"color_intensity\":2.45,\n",
    "  \"hue\":1.04,\n",
    "  \"od280_od315_of_diluted_wines\":2.77,\n",
    "  \"proline\":562.0\n",
    "}'\n",
    "```\n",
    "\n",
    "Or you can use a `JSON` file to avoid typing a long command like this:\n",
    "\n",
    "```bash\n",
    "curl -X POST http://localhost:80/predict \\\n",
    "    -d @./wine-examples/1.json \\\n",
    "    -H \"Content-Type: application/json\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's understand the flags used:\n",
    "- `-X`: Allows you to specify the request type. In this case it is a `POST` request.\n",
    "- `-d`: Stands for `data` and allows you to attach data to the request.\n",
    "- `-H`: Stands for `Headers` and it allows you to pass additional information through the request. In this case it is used to the tell the server that the data is sent in a `JSON` format.\n",
    "\n",
    "\n",
    "There is a directory called `wine-examples` that includes three files, one for each class of wine. Use those to try out the server and also pass in some random values to see what you get!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
